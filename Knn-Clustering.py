# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uY3k5pgKtKYsC1F0niYhA29_HOf4EKP0
"""

import numpy as np
from keras.datasets import mnist
from matplotlib import pyplot as plt
from keras.utils import np_utils
import random as rd
import operator
import matplotlib.cm as cm
from keras import backend as K
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D

#importing all libraries, modules used in code , importing dataset used

#labels = [‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’]

#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
(x_train, y_train), (x_test, y_test) = mnist.load_data()
#loading data set., ued here:cifar10
print(type(x_train))
print(type(x_test))
print(type(y_train))
print(type(y_test))
img_rows, img_cols = 28, 28
image_index = 7777 
print(y_train[image_index])
#printing one of pictures in dataset to make sure its loaded correctly
plt.imshow(x_train[image_index], cmap='Greys')

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)
plt.gray()
plt.figure(figsize = (10,9))
#printing 9 pictures of different data in dataset
for i in range(9):
    plt.subplot(3,3,i+1)
    plt.imshow(x_train[i])

#training the data and transforming it to pixels    
x_train = x_train.astype('float32') 
x_test = x_test.astype('float32')

#training labels 
#one_hot_encoder = OneHotEncoder(sparse=False)
#one_hot_encoder.fit(y_train)
#y_train = one_hot_encoder.transform(y_train)
#y_test = one_hot_encoder.transform(y_test)

#normalization 
x_train = x_train/255.0
x_test = x_test/255.0

print(x_train.min())
print(x_train.max())

#transforming each picture into a vector so we can run dataset and cluster them 
#2 dimention to 3 dimention
X_train = x_train.reshape(len(x_train),-1)
X_test = x_test.reshape(len(x_test),-1)

#X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)
#X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)
#input_shape = (X_train.shape[1], X_train.shape[2], 1)

print(X_train.shape)
print(X_test.shape)


#def retrieve_info(cluster_labels,y_train):
# Associates most probable label with each cluster in KMeans model
#returns: dictionary of clusters assigned to each label
 
# Initiazizing
#reference_labels = {}
# For loop to run through each label of cluster label
#for i in range(len(np.unique(kmeans.labels_))):
#index = np.where(cluster_labels == i,1,0)
 # num = np.bincount(y_train[index==1]).argmax()
 # reference_labels[i] = num
#return reference_labels

#print(reference_labels)

#reference_labels = retrieve_info(kmeans.labels_,y_train)
#number_labels = np.random.rand(len(kmeans.labels_))
#for i in range(len(kmeans.labels_)):
 # number_labels[i] = reference_labels[kmeans.labels_[i]]

#initialization of clustering loop

num_of_iterations=5
k=10

m=X_train.shape[0]  #number of iterations
n=X_train.shape[1]  

Output={}  #our dictionary
oldcentroids={}

#initializing random centroids to start with

Centroids=np.array([]).reshape(n,0)

ok = True  # if a change was made and continue clustering
for i in range(k):
    rand=rd.randint(0,m-1)
    Centroids=np.c_[Centroids,X_train[rand]]

#ok = update_clustering(norm_data, clustering, means) 
    if ok == False:
      break  # done    
#calculating euclidian distance between centroids for clustering 

#assumend that convergence with 5 iterations/ bettwer to use tolerance 
#between centroids difference but was not working

for i in range (num_of_iterations):
    EuclidianDistance=np.array([]).reshape(m,0)
    Output={}
    print(i)
    for j in range(k):
        tempDist=np.sum((X_train-Centroids[:,j])**2,axis=1)
        EuclidianDistance=np.c_[EuclidianDistance,tempDist]
    
    for l in range(k):
        tempDist=np.sum((X_train-Centroids[:,l])**2,axis=1)
        EuclidianDistance=np.c_[EuclidianDistance,tempDist]
        
    C=np.argmin(EuclidianDistance,axis=1)+1
    Y={}
        

    for j in range(k):
        Y[j+1]=np.array([]).reshape(n,0)
    
    for i in range(m):
        print("loop number")
        print(i)
        Y[C[i]]=np.c_[Y[C[i]],X_train[i]]
     
    for j in range(k):
        Y[j+1]=Y[j+1].T
#regrouping and assigning     
    for j in range(k):
        Centroids[:,j]=np.mean(Y[j+1],axis=0)
        
        
    Output = Y

#for each group we get an array , reshape it into the form of 28*28 pixels (each pic)
#and print it so we can see each cluster 

now = Output.get(1)
print ("cluster 1")
for i in range(9):
    see=now[i].reshape(28,28)
    plt.subplot(3,3,i+1)
    plt.imshow(see)
    plt.show

now = Output.get(2)
print ("cluster 4")
for i in range(9):
    see=now[i].reshape(28,28)
    plt.subplot(3,3,i+1)
    plt.imshow(see)

now = Output.get(3)
print ("cluster 3")
for i in range(9):
    see=now[i].reshape(28,28)
    plt.subplot(3,3,i+1)
    plt.imshow(see)

now = Output.get(4)
print ("cluster 4")
for i in range(9):
    see=now[i].reshape(28,28)
    plt.subplot(3,3,i+1)
    plt.imshow(see)

now = Output.get(5)
print ("cluster 5")
for i in range(9):
    see=now[i].reshape(28,28)
    plt.subplot(3,3,i+1)
    plt.imshow(see)

now = Output.get(6)
print ("cluster 6")
for i in range(9):
    see=now[i].reshape(28,28)
    plt.subplot(3,3,i+1)
    plt.imshow(see)

now = Output.get(7)
print ("cluster 7")
for i in range(9):
    see=now[i].reshape(28,28)
    plt.subplot(3,3,i+1)
    plt.imshow(see)

now = Output.get(8)
print ("cluster 8")
for i in range(9):
    see=now[i].reshape(28,28)
    plt.subplot(3,3,i+1)
    plt.imshow(see)

now = Output.get(9)
print ("cluster 8")
for i in range(9):
    see=now[i].reshape(28,28)
    plt.subplot(3,3,i+1)
    plt.imshow(see)

now = Output.get(10)
print ("cluster 10")
for i in range(9):
    see=now[i].reshape(28,28)
    plt.subplot(3,3,i+1)
    plt.imshow(see)